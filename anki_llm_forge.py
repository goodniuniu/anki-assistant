"""
Anki-LLM-Forge: é€šç”¨å‹ Anki å¡ç‰‡å¢å¼ºå·¥å…·
ä¸€ä¸ªé…ç½®é©±åŠ¨çš„ã€æ”¯æŒå¤šåœºæ™¯çš„ Anki å¡ç‰‡å†…å®¹ç”Ÿæˆç³»ç»Ÿ
"""

import pandas as pd
import google.generativeai as genai
import os
import time
import json
import logging
import argparse
from pathlib import Path
from tqdm import tqdm
import re
from typing import Dict, List, Optional, Any
from abc import ABC, abstractmethod


# ================= AI æœåŠ¡å•†æ¥å£ =================
class AIProvider(ABC):
    """AI æœåŠ¡å•†æŠ½è±¡åŸºç±»"""

    def __init__(self, config: Dict):
        self.config = config
        self.logger = logging.getLogger(__name__)

    @abstractmethod
    def generate_content(self, prompt: str, system_prompt: str = "") -> str:
        """ç”Ÿæˆå†…å®¹ï¼Œå­ç±»å¿…é¡»å®ç°"""
        pass


class GeminiProvider(AIProvider):
    """Google Gemini æœåŠ¡å•†"""

    def __init__(self, config: Dict):
        super().__init__(config)
        os.environ["GOOGLE_API_KEY"] = config["api_key"]
        genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
        self.model = genai.GenerativeModel(config['model'])
        self.logger.info(f"å·²åˆå§‹åŒ– Gemini æ¨¡å‹: {config['model']}")

    def generate_content(self, prompt: str, system_prompt: str = "") -> str:
        """ä½¿ç”¨ Gemini ç”Ÿæˆå†…å®¹"""
        response = self.model.generate_content(prompt)
        return response.text


class QiniuProvider(AIProvider):
    """ä¸ƒç‰›äº‘ AI æœåŠ¡å•†ï¼ˆDeepSeekï¼‰"""

    def __init__(self, config: Dict):
        super().__init__(config)
        try:
            from openai import OpenAI
            self.client = OpenAI(
                base_url=config["base_url"],
                api_key=config["api_key"]
            )
            self.model = config['model']
            self.logger.info(f"å·²åˆå§‹åŒ–ä¸ƒç‰›äº‘ AI æ¨¡å‹: {config['model']}")
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")

    def generate_content(self, prompt: str, system_prompt: str = "") -> str:
        """ä½¿ç”¨ä¸ƒç‰›äº‘ AI ç”Ÿæˆå†…å®¹"""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=False,
            max_tokens=4096
        )
        return response.choices[0].message.content


def create_ai_provider(config: Dict, provider_name: str) -> AIProvider:
    """
    å·¥å‚æ–¹æ³•ï¼šæ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”çš„ AI æœåŠ¡å•†å®ä¾‹
    """
    if provider_name == "gemini":
        if "gemini" not in config:
            raise ValueError("é…ç½®ä¸­ç¼ºå°‘ gemini é…ç½®é¡¹")
        return GeminiProvider(config["gemini"])

    elif provider_name in ["qiniu", "deepseek"]:
        if "qiniu" not in config:
            raise ValueError("é…ç½®ä¸­ç¼ºå°‘ qiniu é…ç½®é¡¹")
        return QiniuProvider(config["qiniu"])

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æœåŠ¡å•†: {provider_name}ï¼Œè¯·é€‰æ‹© 'gemini' æˆ– 'qiniu'")


# ================= Profile ç®¡ç† =================
class Profile:
    """ä»»åŠ¡åœºæ™¯é…ç½®ç±»"""

    def __init__(self, profile_name: str, profile_config: Dict):
        self.name = profile_name
        self.description = profile_config.get("description", "")
        self.system_prompt = profile_config.get("system_prompt", "")
        self.user_prompt_template = profile_config.get("user_prompt_template", "")
        self.output_fields = profile_config.get("output_fields", [])
        self.anki_fields = profile_config.get("anki_fields", [])
        self.field_mapping = profile_config.get("field_mapping", {})

    def validate(self) -> bool:
        """éªŒè¯ Profile é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        if not self.user_prompt_template:
            raise ValueError(f"Profile '{self.name}' ç¼ºå°‘ user_prompt_template")
        if not self.output_fields:
            raise ValueError(f"Profile '{self.name}' ç¼ºå°‘ output_fields")
        if not self.anki_fields:
            raise ValueError(f"Profile '{self.name}' ç¼ºå°‘ anki_fields")
        if not self.field_mapping:
            raise ValueError(f"Profile '{self.name}' ç¼ºå°‘ field_mapping")
        return True

    def format_prompt(self, front_text: str) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·æç¤ºè¯"""
        return self.user_prompt_template.format(front_text=front_text)


class ProfileManager:
    """Profile ç®¡ç†å™¨"""

    def __init__(self, profiles_config: Dict):
        self.profiles = {}
        for name, config in profiles_config.items():
            self.profiles[name] = Profile(name, config)

    def get_profile(self, profile_name: str) -> Profile:
        """è·å–æŒ‡å®šçš„ Profile"""
        if profile_name not in self.profiles:
            available = list(self.profiles.keys())
            raise ValueError(
                f"Profile '{profile_name}' ä¸å­˜åœ¨ã€‚"
                f"å¯ç”¨çš„ Profiles: {', '.join(available)}"
            )
        profile = self.profiles[profile_name]
        profile.validate()
        return profile

    def list_profiles(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Profiles"""
        return list(self.profiles.keys())


# ================= Anki å¡ç‰‡ç”Ÿæˆå™¨ =================
class AnkiCardGenerator:
    """Anki å¡ç‰‡ç”Ÿæˆå™¨ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘"""

    def __init__(self, config: Dict):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–å…¨å±€è®¾ç½®
        self.global_settings = config.get("global_settings", {})
        self.provider_name = self.global_settings.get("provider", "gemini")

        # åˆå§‹åŒ– AI æœåŠ¡å•†
        providers_config = config.get("providers", {})
        self.ai_provider = create_ai_provider(providers_config, self.provider_name)

        # åˆå§‹åŒ– Profile ç®¡ç†å™¨
        profiles_config = config.get("profiles", {})
        self.profile_manager = ProfileManager(profiles_config)

        # è·å–å½“å‰æ¿€æ´»çš„ Profile
        active_profile_name = self.global_settings.get("active_profile")
        if not active_profile_name:
            raise ValueError("é…ç½®ä¸­ç¼ºå°‘ active_profileï¼Œè¯·æŒ‡å®šè¦ä½¿ç”¨çš„ Profile")

        self.profile = self.profile_manager.get_profile(active_profile_name)
        self.logger.info(f"ä½¿ç”¨ Profile: {self.profile.name}")
        self.logger.info(f"Profile æè¿°: {self.profile.description}")

    def clean_json_response(self, response_text: str) -> str:
        """æ¸…ç† LLM è¿”å›çš„ JSON å­—ç¬¦ä¸²"""
        # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        clean_text = response_text.replace('```json', '').replace('```', '').strip()
        # ç§»é™¤å¯èƒ½çš„æ³¨é‡Š
        clean_text = re.sub(r'//.*?\n', '\n', clean_text)
        clean_text = re.sub(r'/\*.*?\*/', '', clean_text, flags=re.DOTALL)
        return clean_text

    def call_ai_with_retry(self, prompt: str, max_retries: int = 3, delay: float = 2) -> str:
        """å¸¦é‡è¯•æœºåˆ¶çš„ AI è°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                response_text = self.ai_provider.generate_content(
                    prompt,
                    self.profile.system_prompt
                )
                return response_text
            except Exception as e:
                self.logger.warning(f"AI è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    time.sleep(delay * (attempt + 1))
                else:
                    raise

    def generate_card(self, front_text: str) -> Dict[str, str]:
        """
        ä¸ºå•ä¸ª front_text ç”Ÿæˆå®Œæ•´çš„ Anki å¡ç‰‡

        è¿”å›: dictï¼ŒåŒ…å«æ‰€æœ‰ Anki å­—æ®µ
        """
        # 1. æ ¼å¼åŒ–æç¤ºè¯
        prompt = self.profile.format_prompt(front_text)

        # 2. è°ƒç”¨ AI
        response_text = self.call_ai_with_retry(prompt)

        # 3. æ¸…æ´—å’Œè§£æ JSON
        clean_json = self.clean_json_response(response_text)
        llm_output = json.loads(clean_json)

        # 4. æ˜ å°„åˆ° Anki å­—æ®µ
        card = {"front_text": front_text}

        for llm_field in self.profile.output_fields:
            if llm_field in llm_output:
                # æ ¹æ® field_mapping æ˜ å°„åˆ° Anki å­—æ®µ
                anki_field = self.profile.field_mapping.get(llm_field)
                if anki_field:
                    card[anki_field] = llm_output[llm_field]
                else:
                    card[llm_field] = llm_output[llm_field]
            else:
                self.logger.warning(f"LLM è¿”å›ç¼ºå°‘å­—æ®µ: {llm_field}")
                card[llm_field] = "[å­—æ®µç¼ºå¤±]"

        return card

    def generate_cards(
        self,
        input_data: List[str],
        cache_file: Optional[str] = None,
        progress_callback=None
    ) -> pd.DataFrame:
        """
        æ‰¹é‡ç”Ÿæˆ Anki å¡ç‰‡

        Args:
            input_data: è¾“å…¥æ•°æ®åˆ—è¡¨
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            pd.DataFrame: åŒ…å«æ‰€æœ‰ç”Ÿæˆçš„å¡ç‰‡
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜
        start_index = 0
        if cache_file and Path(cache_file).exists():
            self.logger.info(f"å‘ç°ç¼“å­˜æ–‡ä»¶ï¼Œä»æ–­ç‚¹ç»§ç»­...")
            cache_df = pd.read_csv(cache_file)
            start_index = len(cache_df)

            # ç¡®ä¿åˆ—ä¸€è‡´
            expected_columns = list(self.profile.field_mapping.values())
            if set(cache_df.columns) != set(expected_columns):
                self.logger.warning("ç¼“å­˜æ–‡ä»¶çš„åˆ—ä¸å½“å‰ Profile ä¸åŒ¹é…ï¼Œå°†é‡æ–°ç”Ÿæˆ")
                start_index = 0
                cache_df = pd.DataFrame(columns=expected_columns)

            self.logger.info(f"å·²å®Œæˆ {start_index} æ¡ï¼Œå‰©ä½™ {len(input_data) - start_index} æ¡")

        # åˆå§‹åŒ–ç»“æœ
        results = []
        if start_index > 0:
            cache_df_rows = cache_df.to_dict('records')
            results = cache_df_rows[:start_index]

        # ç”Ÿæˆå¡ç‰‡
        request_delay = self.global_settings.get("request_delay", 1.0)
        max_retries = self.global_settings.get("max_retries", 3)
        save_interval = self.global_settings.get("save_interval", 10)

        for index in tqdm(range(start_index, len(input_data)), desc="ç”Ÿæˆå¡ç‰‡"):
            front_text = input_data[index]

            try:
                # ç”Ÿæˆå¡ç‰‡
                card = self.generate_card(front_text)
                results.append(card)

                self.logger.info(f"âœ… ç¬¬ {index + 1}/{len(input_data)} æ¡ç”ŸæˆæˆåŠŸ")

                # å®šæœŸä¿å­˜è¿›åº¦
                if cache_file and (index + 1) % save_interval == 0:
                    df = pd.DataFrame(results)
                    df.to_csv(cache_file, index=False)
                    self.logger.info(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼ˆå·²å®Œæˆ {index + 1} æ¡ï¼‰")

                # é¿å…è§¦å‘ API é€Ÿç‡é™åˆ¶
                time.sleep(request_delay)

            except json.JSONDecodeError as e:
                self.logger.error(f"âŒ ç¬¬ {index + 1} æ¡ JSON è§£æå¤±è´¥: {e}")
                # åˆ›å»ºä¸€ä¸ªéƒ¨åˆ†å¡«å……çš„å¡ç‰‡
                card = {"front_text": front_text}
                for anki_field in self.profile.anki_fields:
                    if anki_field != "front_text":
                        card[anki_field] = f"[JSON è§£æé”™è¯¯: {str(e)[:50]}]"
                results.append(card)

            except Exception as e:
                self.logger.error(f"âŒ ç¬¬ {index + 1} æ¡å¤„ç†å¤±è´¥: {e}")
                # åˆ›å»ºä¸€ä¸ªéƒ¨åˆ†å¡«å……çš„å¡ç‰‡
                card = {"front_text": front_text}
                for anki_field in self.profile.anki_fields:
                    if anki_field != "front_text":
                        card[anki_field] = f"[å¤„ç†é”™è¯¯: {str(e)[:50]}]"
                results.append(card)

        # æœ€ç»ˆä¿å­˜
        if cache_file:
            df = pd.DataFrame(results)
            df.to_csv(cache_file, index=False)
            self.logger.info("ğŸ’¾ æœ€ç»ˆè¿›åº¦å·²ä¿å­˜")

        return pd.DataFrame(results)


# ================= å·¥å…·å‡½æ•° =================
def load_config(config_file: str) -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_file} æœªæ‰¾åˆ°ï¼")
        print(f"ğŸ’¡ è¯·å¤åˆ¶ config_v3.example.json ä¸º {config_file} å¹¶å¡«å†™é…ç½®")
        raise
    except json.JSONDecodeError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        raise


def setup_logging(log_file: str):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)


def load_input_data(source: str) -> List[str]:
    """
    ä»å¤šç§æ¥æºåŠ è½½è¾“å…¥æ•°æ®
    æ”¯æŒ: list, .txt, .csv, .xlsx
    """
    logger = logging.getLogger(__name__)

    if isinstance(source, list):
        logger.info(f"ä»åˆ—è¡¨åŠ è½½ {len(source)} æ¡æ•°æ®")
        return source

    source_path = Path(source)
    if not source_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {source}")

    if source_path.suffix == '.txt':
        with open(source, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip()]
        logger.info(f"ä» TXT æ–‡ä»¶åŠ è½½ {len(lines)} æ¡æ•°æ®")
        return lines

    elif source_path.suffix == '.csv':
        df = pd.read_csv(source)
        logger.info(f"ä» CSV æ–‡ä»¶åŠ è½½ {len(df)} æ¡æ•°æ®")
        return df.iloc[:, 0].tolist()

    elif source_path.suffix in ['.xlsx', '.xls']:
        df = pd.read_excel(source)
        logger.info(f"ä» Excel æ–‡ä»¶åŠ è½½ {len(df)} æ¡æ•°æ®")
        return df.iloc[:, 0].tolist()

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {source_path.suffix}")


def export_to_anki(df: pd.DataFrame, filename: str, encoding: str = 'utf-8'):
    """å¯¼å‡ºä¸º Anki å¯è¯†åˆ«çš„æ ¼å¼"""
    logger = logging.getLogger(__name__)

    # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
    export_df = df.copy()

    # æ›¿æ¢æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦
    for col in export_df.columns:
        export_df[col] = export_df[col].astype(str).str.replace('\n', '<br>', regex=False)
        export_df[col] = export_df[col].astype(str).str.replace('\r', '', regex=False)
        export_df[col] = export_df[col].astype(str).str.replace('\t', '    ', regex=False)

    # å¯¼å‡º
    export_df.to_csv(filename, sep='\t', index=False, header=False, encoding=encoding)
    logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {filename}")
    logger.info(f"ğŸ“Š å…± {len(df)} å¼ å¡ç‰‡")

    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "="*50)
    print("å¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"  æ€»å¡ç‰‡æ•°: {len(df)}")
    print(f"  å­—æ®µæ•°: {len(df.columns)}")
    print(f"  å­—æ®µåˆ—è¡¨: {', '.join(df.columns)}")
    print(f"  å¯¼å‡ºæ–‡ä»¶: {filename}")
    print("="*50)


# ================= ä¸»ç¨‹åº =================
def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='Anki-LLM-Forge: é€šç”¨å‹ Anki å¡ç‰‡å¢å¼ºå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„ input_file
  python anki_llm_forge.py -c config.json

  # æŒ‡å®šè¾“å…¥æ–‡ä»¶
  python anki_llm_forge.py -c config.json -i my_data.txt

  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python anki_llm_forge.py -c config.json -i input.txt -o output.txt

  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Profiles
  python anki_llm_forge.py -c config.json --list-profiles

  # ä¸´æ—¶åˆ‡æ¢ Profile
  python anki_llm_forge.py -c config.json -p english_vocab

  # æ¸…é™¤ç¼“å­˜é‡æ–°ç”Ÿæˆ
  python anki_llm_forge.py -c config.json --clear-cache
        """
    )

    parser.add_argument(
        '-c', '--config',
        type=str,
        default='config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)'
    )

    parser.add_argument(
        '-i', '--input',
        type=str,
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )

    parser.add_argument(
        '-o', '--output',
        type=str,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )

    parser.add_argument(
        '-p', '--profile',
        type=str,
        help='ä¸´æ—¶åˆ‡æ¢ Profileï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )

    parser.add_argument(
        '--list-profiles',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Profiles'
    )

    parser.add_argument(
        '--clear-cache',
        action='store_true',
        help='æ¸…é™¤ç¼“å­˜æ–‡ä»¶ï¼Œé‡æ–°ç”Ÿæˆæ‰€æœ‰å†…å®¹'
    )

    return parser.parse_args()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    args = parse_arguments()

    try:
        # 1. åŠ è½½é…ç½®
        config = load_config(args.config)

        # 2. è®¾ç½®æ—¥å¿—
        global_settings = config.get("global_settings", {})
        log_file = global_settings.get("log_file", "anki_process.log")
        logger = setup_logging(log_file)

        logger.info("="*50)
        logger.info("Anki-LLM-Forge å¯åŠ¨")
        logger.info(f"é…ç½®æ–‡ä»¶: {args.config}")
        logger.info("="*50)

        # 3. å¤„ç† --list-profiles å‚æ•°
        if args.list_profiles:
            profile_manager = ProfileManager(config.get("profiles", {}))
            profiles = profile_manager.list_profiles()
            print("\nå¯ç”¨çš„ Profiles:")
            print("="*50)
            for name in profiles:
                profile = profile_manager.get_profile(name)
                print(f"\n[{name}]")
                print(f"  æè¿°: {profile.description}")
                print(f"  Anki å­—æ®µ: {', '.join(profile.anki_fields)}")
            print("\n" + "="*50)
            return 0

        # 4. å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶
        if args.profile:
            global_settings["active_profile"] = args.profile
        if args.input:
            global_settings["input_file"] = args.input
        if args.output:
            global_settings["output_file"] = args.output

        # 5. åˆå§‹åŒ–å¡ç‰‡ç”Ÿæˆå™¨
        generator = AnkiCardGenerator(config)

        # 6. æ¸…é™¤ç¼“å­˜ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        cache_file = global_settings.get("cache_file")
        if args.clear_cache and cache_file and Path(cache_file).exists():
            logger.info(f"æ¸…é™¤ç¼“å­˜æ–‡ä»¶: {cache_file}")
            os.remove(cache_file)

        # 7. åŠ è½½è¾“å…¥æ•°æ®
        input_file = global_settings.get("input_file")
        if not input_file:
            print("é”™è¯¯: é…ç½®æ–‡ä»¶ä¸­æœªæŒ‡å®š input_file")
            print("è¯·é€šè¿‡å‘½ä»¤è¡Œå‚æ•° -i æŒ‡å®šï¼Œæˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® input_file")
            return 1

        logger.info("å¼€å§‹åŠ è½½æ•°æ®...")
        input_data = load_input_data(input_file)
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(input_data)} æ¡")

        # 8. ç”Ÿæˆå¡ç‰‡
        logger.info("å¼€å§‹ç”Ÿæˆ Anki å¡ç‰‡...")
        df_cards = generator.generate_cards(
            input_data,
            cache_file=cache_file
        )

        # 9. æ‰“å°é¢„è§ˆ
        print("\n--- æ•°æ®é¢„è§ˆï¼ˆå‰3æ¡ï¼‰---")
        print(df_cards.head(3).to_string())

        # 10. å¯¼å‡º
        output_file = global_settings.get("output_file", "anki_cards.txt")
        output_encoding = global_settings.get("output_encoding", "utf-8")
        export_to_anki(df_cards, output_file, encoding=output_encoding)

        logger.info("="*50)
        logger.info("ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
        logger.info("="*50)

        return 0

    except FileNotFoundError as e:
        logging.getLogger(__name__).error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print(f"\n[é”™è¯¯] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return 1
    except ValueError as e:
        logging.getLogger(__name__).error(f"é…ç½®é”™è¯¯: {e}")
        print(f"\n[é”™è¯¯] é…ç½®é”™è¯¯: {e}")
        return 1
    except Exception as e:
        logging.getLogger(__name__).error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"\n[é”™è¯¯] ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
